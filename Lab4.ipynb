{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os,sys\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from PIL import Image,ImageDraw\n",
    "from os import listdir\n",
    "\n",
    "# 导入不同分类算法的库\n",
    "from sklearn.neighbors import KNeighborsClassifier # Sklearn中kNN算法\n",
    "from sklearn.svm import SVC # SKlearn中SVM算法\n",
    "from sklearn.tree import DecisionTreeClassifier # SKlearn中决策树算法\n",
    "\n",
    "# Sklearn中NB算法\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def img2vec(filename):\n",
    "    returnVector = np.zeros((1,1024))\n",
    "    fr = open(filename)\n",
    "    for i in range(32):\n",
    "        lineStr = fr.readline()\n",
    "        for j in range(32):\n",
    "            returnVector[0,32*i+j]=int(lineStr[j])\n",
    "    return returnVector\n",
    "\n",
    "\n",
    "def loadData(folder_name):    \n",
    "    hwLabels = []\n",
    "    trainingFieldList = listdir(folder_name)\n",
    "    m = len(trainingFieldList)\n",
    "    trainingMat = np.zeros((m,1024))\n",
    "    for i in range(m):\n",
    "        fileName= trainingFieldList[i]\n",
    "        fileStr = fileName.split('.')[0]\n",
    "        classNumStr = int(fileStr.split('_')[0])\n",
    "        hwLabels.append(classNumStr)\n",
    "        trainingMat[i,:]=img2vec(folder_name+fileName)\n",
    "    return trainingMat,hwLabels\n",
    "\n",
    "\n",
    "def cal_accuracy(classifierResult,goldLabels):\n",
    "    mTest = len(classifierResult)\n",
    "    errorCount = 0.0 # 统计识别错误的样本个数\n",
    "    for i in range(mTest):\n",
    "        if classifierResult[i] != goldLabels[i]:\n",
    "            errorCount += 1.0\n",
    "    print(\"\\t 测试样本个数为： %d \" % mTest)\n",
    "    print(\"\\t 预测错误个数为： %d \" % errorCount)\n",
    "    print(\"\\t 预测错误率为： %2.2f%% \" % (errorCount/float(mTest)*100))\n",
    "    print(\"\\t 预测准确率为： %2.2f%%\" % ((1-errorCount/float(mTest))*100)) \n",
    "    return (1-errorCount/float(mTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingMat,hwLabels = loadData('./data/trainingDigits/')\n",
    "testMat,goldLabels = loadData('./data/testDigits/')\n",
    "\n",
    "X = trainingMat\n",
    "y = hwLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 测试样本个数为： 434 \n",
      "\t 预测错误个数为： 14 \n",
      "\t 预测错误率为： 3.23% \n",
      "\t 预测准确率为： 96.77%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.97      0.99        39\n",
      "          1       0.94      0.92      0.93        48\n",
      "          2       1.00      1.00      1.00        45\n",
      "          3       0.96      1.00      0.98        49\n",
      "          4       0.92      1.00      0.96        36\n",
      "          5       0.92      0.95      0.93        37\n",
      "          6       1.00      0.96      0.98        45\n",
      "          7       0.98      1.00      0.99        51\n",
      "          8       0.96      0.87      0.91        30\n",
      "          9       0.98      0.98      0.98        54\n",
      "\n",
      "avg / total       0.97      0.97      0.97       434\n",
      "\n",
      "\n",
      "\t 测试样本个数为： 434 \n",
      "\t 预测错误个数为： 20 \n",
      "\t 预测错误率为： 4.61% \n",
      "\t 预测准确率为： 95.39%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.97      0.97        39\n",
      "          1       0.89      0.98      0.93        48\n",
      "          2       1.00      0.98      0.99        45\n",
      "          3       0.92      1.00      0.96        49\n",
      "          4       0.95      0.97      0.96        36\n",
      "          5       0.97      0.95      0.96        37\n",
      "          6       1.00      0.96      0.98        45\n",
      "          7       0.96      1.00      0.98        51\n",
      "          8       0.96      0.73      0.83        30\n",
      "          9       0.94      0.93      0.93        54\n",
      "\n",
      "avg / total       0.96      0.95      0.95       434\n",
      "\n",
      "\n",
      "\t 测试样本个数为： 434 \n",
      "\t 预测错误个数为： 9 \n",
      "\t 预测错误率为： 2.07% \n",
      "\t 预测准确率为： 97.93%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.97      0.99        39\n",
      "          1       0.94      1.00      0.97        48\n",
      "          2       1.00      1.00      1.00        45\n",
      "          3       0.96      1.00      0.98        49\n",
      "          4       0.97      0.97      0.97        36\n",
      "          5       0.97      0.97      0.97        37\n",
      "          6       1.00      0.96      0.98        45\n",
      "          7       0.98      1.00      0.99        51\n",
      "          8       1.00      0.90      0.95        30\n",
      "          9       0.98      0.98      0.98        54\n",
      "\n",
      "avg / total       0.98      0.98      0.98       434\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "clf1 = SVC(C=100,gamma=0.001,kernel='poly')\n",
    "clf1.fit(X,y)\n",
    "y_true = goldLabels\n",
    "y_pred_1 = clf1.predict(testMat)\n",
    "cal_accuracy(y_pred_1,y_true)\n",
    "print(classification_report(y_true, y_pred_1))\n",
    "print()\n",
    "\n",
    "\n",
    "clf2 = KNeighborsClassifier(algorithm='ball_tree',n_neighbors = 4)\n",
    "clf2.fit(X,y)\n",
    "y_pred_2 = clf2.predict(testMat)\n",
    "cal_accuracy(y_pred_2,y_true)\n",
    "print(classification_report(y_true, y_pred_2))\n",
    "print()\n",
    "\n",
    "clf3=RandomForestClassifier(max_features='sqrt', min_samples_leaf= 1, n_estimators=100)\n",
    "clf3.fit(X,y)\n",
    "y_pred_3 = clf3.predict(testMat)\n",
    "cal_accuracy(y_pred_3,y_true)\n",
    "print(classification_report(y_true, y_pred_3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf0=RandomForestClassifier(max_features='sqrt', min_samples_leaf= 1, n_estimators=300)\n",
      "clf0.fit(X,y)\n",
      "y_pred0=clf0.predict(testMat)\n",
      "clf1=RandomForestClassifier(max_features='sqrt', min_samples_leaf= 1, n_estimators=300)\n",
      "clf1.fit(X,y)\n",
      "y_pred1=clf1.predict(testMat)\n",
      "clf2=RandomForestClassifier(max_features='sqrt', min_samples_leaf= 1, n_estimators=300)\n",
      "clf2.fit(X,y)\n",
      "y_pred2=clf2.predict(testMat)\n",
      "clf3=RandomForestClassifier(max_features='sqrt', min_samples_leaf= 1, n_estimators=300)\n",
      "clf3.fit(X,y)\n",
      "y_pred3=clf3.predict(testMat)\n",
      "clf4=RandomForestClassifier(max_features='sqrt', min_samples_leaf= 1, n_estimators=300)\n",
      "clf4.fit(X,y)\n",
      "y_pred4=clf4.predict(testMat)\n",
      "clf5=RandomForestClassifier(max_features='sqrt', min_samples_leaf= 1, n_estimators=300)\n",
      "clf5.fit(X,y)\n",
      "y_pred5=clf5.predict(testMat)\n",
      "clf6=RandomForestClassifier(max_features='sqrt', min_samples_leaf= 1, n_estimators=300)\n",
      "clf6.fit(X,y)\n",
      "y_pred6=clf6.predict(testMat)\n",
      "clf7=RandomForestClassifier(max_features='sqrt', min_samples_leaf= 1, n_estimators=300)\n",
      "clf7.fit(X,y)\n",
      "y_pred7=clf7.predict(testMat)\n",
      "clf8=RandomForestClassifier(max_features='sqrt', min_samples_leaf= 1, n_estimators=300)\n",
      "clf8.fit(X,y)\n",
      "y_pred8=clf8.predict(testMat)\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 7, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 6, 6, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 6, 8, 8, 8, 8, 8, 8, 8, 1, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 3, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
      "\t 测试样本个数为： 434 \n",
      "\t 预测错误个数为： 12 \n",
      "\t 预测错误率为： 2.76% \n",
      "\t 预测准确率为： 97.24%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.97      0.99        39\n",
      "          1       0.94      0.94      0.94        48\n",
      "          2       1.00      1.00      1.00        45\n",
      "          3       0.96      1.00      0.98        49\n",
      "          4       0.95      0.97      0.96        36\n",
      "          5       1.00      0.97      0.99        37\n",
      "          6       0.98      0.96      0.97        45\n",
      "          7       0.96      1.00      0.98        51\n",
      "          8       0.96      0.90      0.93        30\n",
      "          9       0.98      0.98      0.98        54\n",
      "\n",
      "avg / total       0.97      0.97      0.97       434\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "s = \"RandomForestClassifier(max_features='sqrt', min_samples_leaf= 1, n_estimators=300)\"\n",
    "for i in range(9):\n",
    "    temp = \"clf\"+str(i)+\"=\"+s\n",
    "    exec(temp)\n",
    "    print(temp)\n",
    "    temp = \"clf\"+str(i)+\".fit(X,y)\"\n",
    "    exec(temp)\n",
    "    print(temp)\n",
    "    temp = \"y_pred\"+str(i)+\"=clf\"+str(i)+\".predict(testMat)\"\n",
    "    exec(temp)\n",
    "    print(temp)\n",
    "\n",
    "\n",
    "y_pre = []\n",
    "    \n",
    "for i in range(len(testMat)):\n",
    "    temp = []\n",
    "    for j in range(9):\n",
    "        s = \"temp_num = y_pred\"+str(j)+\"[i]\"\n",
    "        exec(s)\n",
    "        temp.append(temp_num)\n",
    "    a = np.array(temp)\n",
    "    counts = np.bincount(a)\n",
    "    tt = np.argmax(counts)\n",
    "    y_pre.append(int(tt))\n",
    "print(y_pre)\n",
    "cal_accuracy(y_pre,y_true)\n",
    "print(classification_report(y_true, y_pre))\n",
    "# for i in range(len(testMat)):\n",
    "#     if y_pred_3[i]!=y_true[i]:\n",
    "#         print(i,y_pred_1[i],y_pred_2[i],y_pred_3[i],y_true[i])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensemble = [ \"kd_tree_kNN\", \"ball_tree_kNN\", \"brute_kNN\", \n",
    "\t\"linear_SVC\", \"poly_SVC\", \"rbf_SVC\", \"sigmoid_SVC\", \n",
    "\t\"gini_DT\", \"entropy_DT\", \"GaussianNB\", \"MultinomialNB\", \"BernoulliNB\"]\n",
    "mTest = len(testMat)\n",
    "for a in ensemble:\n",
    "    classifierResult = []\n",
    "    print(a + \":\")\n",
    "    if a == \"kd_tree_kNN\":\n",
    "        clf = KNeighborsClassifier(algorithm='kd_tree',n_neighbors = 3)\n",
    "    elif a == \"ball_tree_kNN\":\n",
    "        clf = KNeighborsClassifier(algorithm='ball_tree', n_neighbors = 3)\n",
    "    elif a == \"brute_kNN\":\n",
    "        clf = KNeighborsClassifier(algorithm='brute', n_neighbors = 3)\n",
    "    elif a == \"linear_SVC\":\n",
    "        clf = SVC(C=1.0,kernel='linear')\n",
    "    elif a == \"poly_SVC\":\n",
    "        clf = SVC(C=1.0,kernel='poly')\n",
    "    elif a == \"rbf_SVC\":\n",
    "        clf = SVC(C=1.0,kernel='rbf')\n",
    "    elif a == \"sigmoid_SVC\":\n",
    "        clf = SVC(C=1.0,kernel='sigmoid')\n",
    "    elif a == \"gini_DT\":\n",
    "        clf = DecisionTreeClassifier(criterion='gini', random_state=0)\n",
    "    elif a == \"entropy_DT\":\n",
    "        clf = DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
    "    elif a == \"GaussianNB\":\n",
    "        clf = GaussianNB()\n",
    "    elif a == \"MultinomialNB\":\n",
    "        clf = MultinomialNB()\n",
    "    elif a == \"BernoulliNB\":\n",
    "        clf = BernoulliNB()\n",
    "\n",
    "    clf.fit(trainingMat, hwLabels) # 训练模型\n",
    "    classifierResult = clf.predict(testMat) # 应用模型，预测测试数据\n",
    "\n",
    "    cal_accuracy(classifierResult,goldLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117 3 5 5 204\n",
      "196 3 7 2 276\n",
      "328 8 9 8 395\n",
      "544 5 8 5 59\n",
      "650 2 2 8 685\n",
      "664 7 4 7 698\n",
      "699 4 4 8 729\n",
      "732 1 3 1 759\n"
     ]
    }
   ],
   "source": [
    "#得到预测结果\n",
    "def loadData_test(folder_name):    \n",
    "    trainingFieldList = listdir(folder_name)\n",
    "    m = len(trainingFieldList)\n",
    "    trainingMat = np.zeros((m,1024))\n",
    "    file_name_list = []\n",
    "    for i in range(m):\n",
    "        fileName= trainingFieldList[i]\n",
    "        fileStr = fileName.split('.')[0]\n",
    "        file_name_list.append(fileStr)\n",
    "        trainingMat[i,:]=img2vec(folder_name+fileName)\n",
    "    return trainingMat,file_name_list\n",
    "\n",
    "trainingMat,hwLabels = loadData('./data/trainingDigits/')\n",
    "testMat,filename_list = loadData_test('./testfile_8/')\n",
    "mTest = len(testMat)\n",
    "X = trainingMat\n",
    "y = hwLabels\n",
    "\n",
    "clf_1=RandomForestClassifier(max_features='sqrt', min_samples_leaf= 1, n_estimators=500)\n",
    "clf_1.fit(X,y)\n",
    "y_pred_1 = clf_1.predict(testMat)\n",
    "y_pred_2 = clf3.predict(testMat)\n",
    "clf_2=RandomForestClassifier(max_features='sqrt', min_samples_leaf= 1, n_estimators=100)\n",
    "clf_2.fit(X,y)\n",
    "y_pred_3 = clf_2.predict(testMat)\n",
    "\n",
    "for i in range(mTest):\n",
    "    if y_pred_1[i]!= y_pred_2[i] or y_pred_1[i]!=y_pred_3[i] or y_pred_3[i]!=y_pred_2[i]:\n",
    "        print(i,y_pred_1[i],y_pred_2[i],y_pred_3[i],filename_list[i] )\n",
    "  \n",
    "        \n",
    "# file = open('./re.txt', 'w')\n",
    "\n",
    "# for i in range(mTest):\n",
    "# \tfile.write(filename_list[i] + '\\t' + str(y_pred_1[i]) + '\\n')\n",
    "\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 测试样本个数为： 434 \n",
      "\t 预测错误个数为： 14 \n",
      "\t 预测错误率为： 3.23% \n",
      "\t 预测准确率为： 96.77%\n",
      "\n",
      "\t 测试样本个数为： 434 \n",
      "\t 预测错误个数为： 20 \n",
      "\t 预测错误率为： 4.61% \n",
      "\t 预测准确率为： 95.39%\n",
      "\n",
      "\t 测试样本个数为： 434 \n",
      "\t 预测错误个数为： 11 \n",
      "\t 预测错误率为： 2.53% \n",
      "\t 预测准确率为： 97.47%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9746543778801844"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainingMat,hwLabels = loadData('./data/trainingDigits/')\n",
    "testMat,goldLabels = loadData('./data/testDigits/')\n",
    "\n",
    "X = trainingMat\n",
    "y = hwLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 100, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.962 (+/-0.050) for {'C': 1, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "0.911 (+/-0.065) for {'C': 1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.962 (+/-0.050) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.913 (+/-0.070) for {'C': 1, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.925 (+/-0.062) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.747 (+/-0.063) for {'C': 1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.972 (+/-0.040) for {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "0.962 (+/-0.046) for {'C': 10, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.972 (+/-0.040) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.962 (+/-0.047) for {'C': 10, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.960 (+/-0.053) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.747 (+/-0.063) for {'C': 10, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.971 (+/-0.040) for {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "0.974 (+/-0.041) for {'C': 100, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.973 (+/-0.040) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.974 (+/-0.042) for {'C': 100, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.970 (+/-0.039) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.747 (+/-0.063) for {'C': 100, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.971 (+/-0.040) for {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "0.974 (+/-0.042) for {'C': 1000, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.973 (+/-0.040) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.974 (+/-0.042) for {'C': 1000, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.969 (+/-0.042) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.913 (+/-0.070) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.969 (+/-0.042) for {'C': 1, 'kernel': 'linear'}\n",
      "0.951 (+/-0.049) for {'C': 1, 'kernel': 'sigmoid'}\n",
      "0.969 (+/-0.042) for {'C': 10, 'kernel': 'linear'}\n",
      "0.968 (+/-0.037) for {'C': 10, 'kernel': 'sigmoid'}\n",
      "0.969 (+/-0.042) for {'C': 100, 'kernel': 'linear'}\n",
      "0.969 (+/-0.042) for {'C': 100, 'kernel': 'sigmoid'}\n",
      "0.969 (+/-0.042) for {'C': 1000, 'kernel': 'linear'}\n",
      "0.969 (+/-0.042) for {'C': 1000, 'kernel': 'sigmoid'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.97      0.99        39\n",
      "          1       0.94      0.92      0.93        48\n",
      "          2       1.00      1.00      1.00        45\n",
      "          3       0.96      1.00      0.98        49\n",
      "          4       0.92      1.00      0.96        36\n",
      "          5       0.92      0.95      0.93        37\n",
      "          6       1.00      0.96      0.98        45\n",
      "          7       0.98      1.00      0.99        51\n",
      "          8       0.96      0.87      0.91        30\n",
      "          9       0.98      0.98      0.98        54\n",
      "\n",
      "avg / total       0.97      0.97      0.97       434\n",
      "\n",
      "\n",
      "使用测试集验证平均准确率:\n",
      "SCV {'C': 100, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "\t 测试样本个数为： 434 \n",
      "\t 预测错误个数为： 14 \n",
      "\t 预测错误率为： 3.23% \n",
      "\t 预测准确率为： 96.77%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.967741935483871"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# Split the dataset in two equal parts\n",
    "X_train,y_train = X, y\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf','poly'],\n",
    "                     'gamma': ['auto',1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear','sigmoid'],\n",
    "                     'C': [1, 10, 100, 1000]}\n",
    "                   ]\n",
    "        \n",
    "score = 'precision'\n",
    "\n",
    "print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "print()\n",
    "\n",
    "clf = GridSearchCV(SVC(), tuned_parameters, cv=10,\n",
    "                   scoring='%s_macro' % score)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "\n",
    "y_true = goldLabels\n",
    "y_pred = clf.predict(testMat)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n",
    "print(\"使用测试集验证平均准确率:\")\n",
    "print(\"SCV\",clf.best_params_)\n",
    "cal_accuracy(y_pred,y_true)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 100}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.890 (+/-0.083) for {'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 5}\n",
      "0.924 (+/-0.050) for {'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 10}\n",
      "0.953 (+/-0.035) for {'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 20}\n",
      "0.957 (+/-0.035) for {'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 50}\n",
      "0.965 (+/-0.044) for {'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 100}\n",
      "0.963 (+/-0.038) for {'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 200}\n",
      "0.963 (+/-0.042) for {'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 500}\n",
      "0.888 (+/-0.084) for {'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 5}\n",
      "0.910 (+/-0.049) for {'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 10}\n",
      "0.942 (+/-0.045) for {'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 20}\n",
      "0.943 (+/-0.044) for {'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "0.950 (+/-0.040) for {'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 100}\n",
      "0.949 (+/-0.053) for {'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 200}\n",
      "0.950 (+/-0.047) for {'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 500}\n",
      "0.864 (+/-0.053) for {'max_features': 'sqrt', 'min_samples_leaf': 10, 'n_estimators': 5}\n",
      "0.913 (+/-0.029) for {'max_features': 'sqrt', 'min_samples_leaf': 10, 'n_estimators': 10}\n",
      "0.920 (+/-0.044) for {'max_features': 'sqrt', 'min_samples_leaf': 10, 'n_estimators': 20}\n",
      "0.932 (+/-0.047) for {'max_features': 'sqrt', 'min_samples_leaf': 10, 'n_estimators': 50}\n",
      "0.937 (+/-0.047) for {'max_features': 'sqrt', 'min_samples_leaf': 10, 'n_estimators': 100}\n",
      "0.935 (+/-0.042) for {'max_features': 'sqrt', 'min_samples_leaf': 10, 'n_estimators': 200}\n",
      "0.934 (+/-0.047) for {'max_features': 'sqrt', 'min_samples_leaf': 10, 'n_estimators': 500}\n",
      "0.760 (+/-0.075) for {'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 5}\n",
      "0.830 (+/-0.047) for {'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 10}\n",
      "0.868 (+/-0.065) for {'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 20}\n",
      "0.880 (+/-0.068) for {'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 50}\n",
      "0.879 (+/-0.067) for {'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 100}\n",
      "0.895 (+/-0.057) for {'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 200}\n",
      "0.886 (+/-0.056) for {'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 500}\n",
      "0.684 (+/-0.037) for {'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 5}\n",
      "0.775 (+/-0.045) for {'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 10}\n",
      "0.833 (+/-0.037) for {'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 20}\n",
      "0.830 (+/-0.061) for {'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 50}\n",
      "0.835 (+/-0.069) for {'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 100}\n",
      "0.848 (+/-0.085) for {'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 200}\n",
      "0.851 (+/-0.063) for {'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 500}\n",
      "0.569 (+/-0.118) for {'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 5}\n",
      "0.700 (+/-0.102) for {'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 10}\n",
      "0.744 (+/-0.066) for {'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 20}\n",
      "0.798 (+/-0.065) for {'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 50}\n",
      "0.821 (+/-0.032) for {'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 100}\n",
      "0.821 (+/-0.087) for {'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 200}\n",
      "0.831 (+/-0.082) for {'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 500}\n",
      "0.561 (+/-0.138) for {'max_features': 'sqrt', 'min_samples_leaf': 200, 'n_estimators': 5}\n",
      "0.667 (+/-0.182) for {'max_features': 'sqrt', 'min_samples_leaf': 200, 'n_estimators': 10}\n",
      "0.714 (+/-0.113) for {'max_features': 'sqrt', 'min_samples_leaf': 200, 'n_estimators': 20}\n",
      "0.793 (+/-0.052) for {'max_features': 'sqrt', 'min_samples_leaf': 200, 'n_estimators': 50}\n",
      "0.793 (+/-0.066) for {'max_features': 'sqrt', 'min_samples_leaf': 200, 'n_estimators': 100}\n",
      "0.806 (+/-0.070) for {'max_features': 'sqrt', 'min_samples_leaf': 200, 'n_estimators': 200}\n",
      "0.793 (+/-0.055) for {'max_features': 'sqrt', 'min_samples_leaf': 200, 'n_estimators': 500}\n",
      "0.881 (+/-0.033) for {'max_features': 'log2', 'min_samples_leaf': 1, 'n_estimators': 5}\n",
      "0.929 (+/-0.044) for {'max_features': 'log2', 'min_samples_leaf': 1, 'n_estimators': 10}\n",
      "0.941 (+/-0.047) for {'max_features': 'log2', 'min_samples_leaf': 1, 'n_estimators': 20}\n",
      "0.959 (+/-0.029) for {'max_features': 'log2', 'min_samples_leaf': 1, 'n_estimators': 50}\n",
      "0.957 (+/-0.040) for {'max_features': 'log2', 'min_samples_leaf': 1, 'n_estimators': 100}\n",
      "0.963 (+/-0.036) for {'max_features': 'log2', 'min_samples_leaf': 1, 'n_estimators': 200}\n",
      "0.964 (+/-0.038) for {'max_features': 'log2', 'min_samples_leaf': 1, 'n_estimators': 500}\n",
      "0.864 (+/-0.053) for {'max_features': 'log2', 'min_samples_leaf': 5, 'n_estimators': 5}\n",
      "0.918 (+/-0.050) for {'max_features': 'log2', 'min_samples_leaf': 5, 'n_estimators': 10}\n",
      "0.930 (+/-0.042) for {'max_features': 'log2', 'min_samples_leaf': 5, 'n_estimators': 20}\n",
      "0.942 (+/-0.042) for {'max_features': 'log2', 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "0.953 (+/-0.040) for {'max_features': 'log2', 'min_samples_leaf': 5, 'n_estimators': 100}\n",
      "0.948 (+/-0.042) for {'max_features': 'log2', 'min_samples_leaf': 5, 'n_estimators': 200}\n",
      "0.952 (+/-0.043) for {'max_features': 'log2', 'min_samples_leaf': 5, 'n_estimators': 500}\n",
      "0.840 (+/-0.098) for {'max_features': 'log2', 'min_samples_leaf': 10, 'n_estimators': 5}\n",
      "0.897 (+/-0.083) for {'max_features': 'log2', 'min_samples_leaf': 10, 'n_estimators': 10}\n",
      "0.921 (+/-0.053) for {'max_features': 'log2', 'min_samples_leaf': 10, 'n_estimators': 20}\n",
      "0.927 (+/-0.049) for {'max_features': 'log2', 'min_samples_leaf': 10, 'n_estimators': 50}\n",
      "0.936 (+/-0.043) for {'max_features': 'log2', 'min_samples_leaf': 10, 'n_estimators': 100}\n",
      "0.939 (+/-0.043) for {'max_features': 'log2', 'min_samples_leaf': 10, 'n_estimators': 200}\n",
      "0.941 (+/-0.044) for {'max_features': 'log2', 'min_samples_leaf': 10, 'n_estimators': 500}\n",
      "0.743 (+/-0.143) for {'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 5}\n",
      "0.805 (+/-0.081) for {'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 10}\n",
      "0.842 (+/-0.059) for {'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 20}\n",
      "0.890 (+/-0.047) for {'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 50}\n",
      "0.903 (+/-0.053) for {'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 100}\n",
      "0.901 (+/-0.055) for {'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 200}\n",
      "0.914 (+/-0.052) for {'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 500}\n",
      "0.683 (+/-0.122) for {'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 5}\n",
      "0.771 (+/-0.071) for {'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 10}\n",
      "0.819 (+/-0.055) for {'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 20}\n",
      "0.869 (+/-0.040) for {'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 50}\n",
      "0.881 (+/-0.050) for {'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 100}\n",
      "0.881 (+/-0.060) for {'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 200}\n",
      "0.887 (+/-0.051) for {'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 500}\n",
      "0.611 (+/-0.108) for {'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 5}\n",
      "0.719 (+/-0.080) for {'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 10}\n",
      "0.828 (+/-0.072) for {'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 20}\n",
      "0.837 (+/-0.047) for {'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 50}\n",
      "0.864 (+/-0.066) for {'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 100}\n",
      "0.865 (+/-0.059) for {'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 200}\n",
      "0.883 (+/-0.053) for {'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 500}\n",
      "0.548 (+/-0.168) for {'max_features': 'log2', 'min_samples_leaf': 200, 'n_estimators': 5}\n",
      "0.661 (+/-0.101) for {'max_features': 'log2', 'min_samples_leaf': 200, 'n_estimators': 10}\n",
      "0.763 (+/-0.033) for {'max_features': 'log2', 'min_samples_leaf': 200, 'n_estimators': 20}\n",
      "0.828 (+/-0.045) for {'max_features': 'log2', 'min_samples_leaf': 200, 'n_estimators': 50}\n",
      "0.841 (+/-0.039) for {'max_features': 'log2', 'min_samples_leaf': 200, 'n_estimators': 100}\n",
      "0.861 (+/-0.044) for {'max_features': 'log2', 'min_samples_leaf': 200, 'n_estimators': 200}\n",
      "0.869 (+/-0.064) for {'max_features': 'log2', 'min_samples_leaf': 200, 'n_estimators': 500}\n",
      "0.898 (+/-0.034) for {'max_features': 0.2, 'min_samples_leaf': 1, 'n_estimators': 5}\n",
      "0.929 (+/-0.040) for {'max_features': 0.2, 'min_samples_leaf': 1, 'n_estimators': 10}\n",
      "0.943 (+/-0.052) for {'max_features': 0.2, 'min_samples_leaf': 1, 'n_estimators': 20}\n",
      "0.949 (+/-0.051) for {'max_features': 0.2, 'min_samples_leaf': 1, 'n_estimators': 50}\n",
      "0.952 (+/-0.053) for {'max_features': 0.2, 'min_samples_leaf': 1, 'n_estimators': 100}\n",
      "0.956 (+/-0.045) for {'max_features': 0.2, 'min_samples_leaf': 1, 'n_estimators': 200}\n",
      "0.954 (+/-0.052) for {'max_features': 0.2, 'min_samples_leaf': 1, 'n_estimators': 500}\n",
      "0.885 (+/-0.078) for {'max_features': 0.2, 'min_samples_leaf': 5, 'n_estimators': 5}\n",
      "0.914 (+/-0.046) for {'max_features': 0.2, 'min_samples_leaf': 5, 'n_estimators': 10}\n",
      "0.930 (+/-0.064) for {'max_features': 0.2, 'min_samples_leaf': 5, 'n_estimators': 20}\n",
      "0.937 (+/-0.048) for {'max_features': 0.2, 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "0.939 (+/-0.043) for {'max_features': 0.2, 'min_samples_leaf': 5, 'n_estimators': 100}\n",
      "0.934 (+/-0.049) for {'max_features': 0.2, 'min_samples_leaf': 5, 'n_estimators': 200}\n",
      "0.942 (+/-0.044) for {'max_features': 0.2, 'min_samples_leaf': 5, 'n_estimators': 500}\n",
      "0.869 (+/-0.047) for {'max_features': 0.2, 'min_samples_leaf': 10, 'n_estimators': 5}\n",
      "0.896 (+/-0.048) for {'max_features': 0.2, 'min_samples_leaf': 10, 'n_estimators': 10}\n",
      "0.917 (+/-0.059) for {'max_features': 0.2, 'min_samples_leaf': 10, 'n_estimators': 20}\n",
      "0.913 (+/-0.051) for {'max_features': 0.2, 'min_samples_leaf': 10, 'n_estimators': 50}\n",
      "0.923 (+/-0.062) for {'max_features': 0.2, 'min_samples_leaf': 10, 'n_estimators': 100}\n",
      "0.920 (+/-0.051) for {'max_features': 0.2, 'min_samples_leaf': 10, 'n_estimators': 200}\n",
      "0.919 (+/-0.053) for {'max_features': 0.2, 'min_samples_leaf': 10, 'n_estimators': 500}\n",
      "0.772 (+/-0.110) for {'max_features': 0.2, 'min_samples_leaf': 50, 'n_estimators': 5}\n",
      "0.796 (+/-0.078) for {'max_features': 0.2, 'min_samples_leaf': 50, 'n_estimators': 10}\n",
      "0.801 (+/-0.120) for {'max_features': 0.2, 'min_samples_leaf': 50, 'n_estimators': 20}\n",
      "0.838 (+/-0.094) for {'max_features': 0.2, 'min_samples_leaf': 50, 'n_estimators': 50}\n",
      "0.819 (+/-0.091) for {'max_features': 0.2, 'min_samples_leaf': 50, 'n_estimators': 100}\n",
      "0.834 (+/-0.083) for {'max_features': 0.2, 'min_samples_leaf': 50, 'n_estimators': 200}\n",
      "0.835 (+/-0.100) for {'max_features': 0.2, 'min_samples_leaf': 50, 'n_estimators': 500}\n",
      "0.633 (+/-0.158) for {'max_features': 0.2, 'min_samples_leaf': 100, 'n_estimators': 5}\n",
      "0.686 (+/-0.125) for {'max_features': 0.2, 'min_samples_leaf': 100, 'n_estimators': 10}\n",
      "0.749 (+/-0.041) for {'max_features': 0.2, 'min_samples_leaf': 100, 'n_estimators': 20}\n",
      "0.733 (+/-0.133) for {'max_features': 0.2, 'min_samples_leaf': 100, 'n_estimators': 50}\n",
      "0.745 (+/-0.070) for {'max_features': 0.2, 'min_samples_leaf': 100, 'n_estimators': 100}\n",
      "0.751 (+/-0.091) for {'max_features': 0.2, 'min_samples_leaf': 100, 'n_estimators': 200}\n",
      "0.765 (+/-0.071) for {'max_features': 0.2, 'min_samples_leaf': 100, 'n_estimators': 500}\n",
      "0.550 (+/-0.174) for {'max_features': 0.2, 'min_samples_leaf': 150, 'n_estimators': 5}\n",
      "0.670 (+/-0.097) for {'max_features': 0.2, 'min_samples_leaf': 150, 'n_estimators': 10}\n",
      "0.648 (+/-0.171) for {'max_features': 0.2, 'min_samples_leaf': 150, 'n_estimators': 20}\n",
      "0.679 (+/-0.055) for {'max_features': 0.2, 'min_samples_leaf': 150, 'n_estimators': 50}\n",
      "0.712 (+/-0.053) for {'max_features': 0.2, 'min_samples_leaf': 150, 'n_estimators': 100}\n",
      "0.697 (+/-0.061) for {'max_features': 0.2, 'min_samples_leaf': 150, 'n_estimators': 200}\n",
      "0.724 (+/-0.067) for {'max_features': 0.2, 'min_samples_leaf': 150, 'n_estimators': 500}\n",
      "0.519 (+/-0.181) for {'max_features': 0.2, 'min_samples_leaf': 200, 'n_estimators': 5}\n",
      "0.559 (+/-0.148) for {'max_features': 0.2, 'min_samples_leaf': 200, 'n_estimators': 10}\n",
      "0.635 (+/-0.086) for {'max_features': 0.2, 'min_samples_leaf': 200, 'n_estimators': 20}\n",
      "0.559 (+/-0.116) for {'max_features': 0.2, 'min_samples_leaf': 200, 'n_estimators': 50}\n",
      "0.620 (+/-0.117) for {'max_features': 0.2, 'min_samples_leaf': 200, 'n_estimators': 100}\n",
      "0.660 (+/-0.074) for {'max_features': 0.2, 'min_samples_leaf': 200, 'n_estimators': 200}\n",
      "0.677 (+/-0.035) for {'max_features': 0.2, 'min_samples_leaf': 200, 'n_estimators': 500}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.97      0.99        39\n",
      "          1       0.96      0.96      0.96        48\n",
      "          2       0.96      1.00      0.98        45\n",
      "          3       0.96      1.00      0.98        49\n",
      "          4       0.97      0.97      0.97        36\n",
      "          5       0.97      0.97      0.97        37\n",
      "          6       1.00      0.96      0.98        45\n",
      "          7       0.98      1.00      0.99        51\n",
      "          8       0.97      0.93      0.95        30\n",
      "          9       1.00      0.98      0.99        54\n",
      "\n",
      "avg / total       0.98      0.98      0.98       434\n",
      "\n",
      "\n",
      "使用测试集验证平均准确率:\n",
      "Random Forest {'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 100}\n",
      "\t 测试样本个数为： 434 \n",
      "\t 预测错误个数为： 10 \n",
      "\t 预测错误率为： 2.30% \n",
      "\t 预测准确率为： 97.70%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9769585253456221"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Split the dataset in two equal parts\n",
    "X_train,y_train = X, y\n",
    "\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'n_estimators': [5,10,20,50,100,200,500],\n",
    "                     'max_features': [\"sqrt\",\"log2\",0.2],\n",
    "                     'min_samples_leaf': [1,5,10,50,100,150,200]}\n",
    "                   ]\n",
    "\n",
    "score = 'precision'\n",
    "\n",
    "print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "print()\n",
    "\n",
    "clf = GridSearchCV(RandomForestClassifier(), tuned_parameters, cv=5,\n",
    "                   scoring='%s_macro' % score)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "y_true = goldLabels\n",
    "y_pred = clf.predict(testMat)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n",
    "print(\"使用测试集验证平均准确率:\")\n",
    "print(\"Random Forest\",clf.best_params_)\n",
    "cal_accuracy(y_pred,y_true)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 测试样本个数为： 434 \n",
      "\t 预测错误个数为： 11 \n",
      "\t 预测错误率为： 2.53% \n",
      "\t 预测准确率为： 97.47%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9746543778801844"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_features='sqrt', min_samples_leaf= 1, n_estimators= 200)\n",
    "clf.fit(trainingMat, hwLabels) # 训练模型\n",
    "classifierResult = clf.predict(testMat) # 应用模型，预测测试数据\n",
    "\n",
    "cal_accuracy(classifierResult,goldLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'algorithm': 'ball_tree', 'n_neighbors': 4}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.959 (+/-0.033) for {'algorithm': 'kd_tree', 'n_neighbors': 3}\n",
      "0.959 (+/-0.040) for {'algorithm': 'kd_tree', 'n_neighbors': 4}\n",
      "0.957 (+/-0.036) for {'algorithm': 'kd_tree', 'n_neighbors': 5}\n",
      "0.957 (+/-0.040) for {'algorithm': 'kd_tree', 'n_neighbors': 6}\n",
      "0.957 (+/-0.037) for {'algorithm': 'kd_tree', 'n_neighbors': 7}\n",
      "0.951 (+/-0.044) for {'algorithm': 'kd_tree', 'n_neighbors': 10}\n",
      "0.953 (+/-0.044) for {'algorithm': 'kd_tree', 'n_neighbors': 13}\n",
      "0.953 (+/-0.043) for {'algorithm': 'kd_tree', 'n_neighbors': 15}\n",
      "0.947 (+/-0.046) for {'algorithm': 'kd_tree', 'n_neighbors': 20}\n",
      "0.959 (+/-0.033) for {'algorithm': 'ball_tree', 'n_neighbors': 3}\n",
      "0.960 (+/-0.039) for {'algorithm': 'ball_tree', 'n_neighbors': 4}\n",
      "0.957 (+/-0.036) for {'algorithm': 'ball_tree', 'n_neighbors': 5}\n",
      "0.957 (+/-0.040) for {'algorithm': 'ball_tree', 'n_neighbors': 6}\n",
      "0.957 (+/-0.038) for {'algorithm': 'ball_tree', 'n_neighbors': 7}\n",
      "0.951 (+/-0.045) for {'algorithm': 'ball_tree', 'n_neighbors': 10}\n",
      "0.952 (+/-0.046) for {'algorithm': 'ball_tree', 'n_neighbors': 13}\n",
      "0.952 (+/-0.044) for {'algorithm': 'ball_tree', 'n_neighbors': 15}\n",
      "0.947 (+/-0.044) for {'algorithm': 'ball_tree', 'n_neighbors': 20}\n",
      "0.959 (+/-0.033) for {'algorithm': 'brute', 'n_neighbors': 3}\n",
      "0.959 (+/-0.038) for {'algorithm': 'brute', 'n_neighbors': 4}\n",
      "0.959 (+/-0.035) for {'algorithm': 'brute', 'n_neighbors': 5}\n",
      "0.956 (+/-0.041) for {'algorithm': 'brute', 'n_neighbors': 6}\n",
      "0.957 (+/-0.037) for {'algorithm': 'brute', 'n_neighbors': 7}\n",
      "0.951 (+/-0.042) for {'algorithm': 'brute', 'n_neighbors': 10}\n",
      "0.951 (+/-0.050) for {'algorithm': 'brute', 'n_neighbors': 13}\n",
      "0.952 (+/-0.040) for {'algorithm': 'brute', 'n_neighbors': 15}\n",
      "0.947 (+/-0.044) for {'algorithm': 'brute', 'n_neighbors': 20}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.97      0.97        39\n",
      "          1       0.89      0.98      0.93        48\n",
      "          2       1.00      0.98      0.99        45\n",
      "          3       0.92      1.00      0.96        49\n",
      "          4       0.95      0.97      0.96        36\n",
      "          5       0.97      0.95      0.96        37\n",
      "          6       1.00      0.96      0.98        45\n",
      "          7       0.96      1.00      0.98        51\n",
      "          8       0.96      0.73      0.83        30\n",
      "          9       0.94      0.93      0.93        54\n",
      "\n",
      "avg / total       0.96      0.95      0.95       434\n",
      "\n",
      "\n",
      "使用测试集验证平均准确率:\n",
      "knn {'algorithm': 'ball_tree', 'n_neighbors': 4}\n",
      "\t 测试样本个数为： 434 \n",
      "\t 预测错误个数为： 20 \n",
      "\t 预测错误率为： 4.61% \n",
      "\t 预测准确率为： 95.39%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9539170506912442"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Split the dataset in two equal parts\n",
    "X_train,y_train = X, y\n",
    "\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'algorithm': ['kd_tree','ball_tree','brute'],\n",
    "                     'n_neighbors': [3,4,5,6,7,10,13,15,20]}\n",
    "                   ]\n",
    "\n",
    "score = 'precision'\n",
    "\n",
    "print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "print()\n",
    "\n",
    "clf = GridSearchCV(KNeighborsClassifier(), tuned_parameters, cv=10,\n",
    "                   scoring='%s_macro' % score)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "y_true = goldLabels\n",
    "y_pred = clf.predict(testMat)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n",
    "print(\"使用测试集验证平均准确率:\")\n",
    "print(\"knn\",clf.best_params_)\n",
    "cal_accuracy(y_pred,y_true)\n",
    "\n",
    "\n",
    "\n",
    "# {'algorithm': 'kd_tree', 'n_neighbors': 3}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.784 (+/-0.074) for {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5}\n",
      "0.782 (+/-0.091) for {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 10}\n",
      "0.779 (+/-0.084) for {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 15}\n",
      "0.841 (+/-0.094) for {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5}\n",
      "0.833 (+/-0.090) for {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10}\n",
      "0.822 (+/-0.080) for {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 15}\n",
      "0.831 (+/-0.095) for {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 5}\n",
      "0.828 (+/-0.093) for {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 10}\n",
      "0.827 (+/-0.088) for {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 15}\n",
      "0.841 (+/-0.095) for {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 5}\n",
      "0.840 (+/-0.093) for {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 10}\n",
      "0.824 (+/-0.079) for {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 15}\n",
      "0.833 (+/-0.094) for {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 5}\n",
      "0.831 (+/-0.087) for {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10}\n",
      "0.823 (+/-0.089) for {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 15}\n",
      "0.776 (+/-0.113) for {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5}\n",
      "0.777 (+/-0.125) for {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 10}\n",
      "0.773 (+/-0.113) for {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 15}\n",
      "0.811 (+/-0.106) for {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5}\n",
      "0.816 (+/-0.106) for {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10}\n",
      "0.814 (+/-0.107) for {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 15}\n",
      "0.812 (+/-0.119) for {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 5}\n",
      "0.818 (+/-0.116) for {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 10}\n",
      "0.816 (+/-0.108) for {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 15}\n",
      "0.817 (+/-0.135) for {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 5}\n",
      "0.822 (+/-0.115) for {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 10}\n",
      "0.809 (+/-0.123) for {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 15}\n",
      "0.813 (+/-0.118) for {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5}\n",
      "0.818 (+/-0.117) for {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 10}\n",
      "0.815 (+/-0.118) for {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 15}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.85      0.92        39\n",
      "          1       0.70      0.88      0.78        48\n",
      "          2       0.78      0.69      0.73        45\n",
      "          3       0.89      0.96      0.92        49\n",
      "          4       0.78      0.81      0.79        36\n",
      "          5       0.82      0.84      0.83        37\n",
      "          6       0.91      0.91      0.91        45\n",
      "          7       0.91      0.84      0.88        51\n",
      "          8       0.63      0.63      0.63        30\n",
      "          9       0.88      0.83      0.86        54\n",
      "\n",
      "avg / total       0.84      0.83      0.83       434\n",
      "\n",
      "\n",
      "使用测试集验证平均准确率:\n",
      "DecisionTreeClassifier {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5}\n",
      "\t 测试样本个数为： 434 \n",
      "\t 预测错误个数为： 73 \n",
      "\t 预测错误率为： 16.82% \n",
      "\t 预测准确率为： 83.18%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8317972350230415"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#设置参数矩阵：\n",
    "tuned_parameters = [{'criterion': ['entropy','gini'],\n",
    "              'max_depth': [5,10,15,20,30],\n",
    "              'min_samples_split': [5,10,15]}\n",
    "                   ]\n",
    "\n",
    "# Split the dataset in two equal parts\n",
    "X_train,y_train = X, y\n",
    "\n",
    "\n",
    "score = 'precision'\n",
    "\n",
    "print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "print()\n",
    "\n",
    "clf = GridSearchCV(DecisionTreeClassifier(), tuned_parameters, cv=10,\n",
    "                   scoring='%s_macro' % score)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "y_true = goldLabels\n",
    "y_pred = clf.predict(testMat)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n",
    "print(\"使用测试集验证平均准确率:\")\n",
    "print(\"DecisionTreeClassifier\",clf.best_params_)\n",
    "cal_accuracy(y_pred,y_true)\n",
    "\n",
    "\n",
    "\n",
    "# {'algorithm': 'kd_tree', 'n_neighbors': 3}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
      "[0 0 4 0 4 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 4 0 4 0 0\n",
      " 0 0 1 6 1 1 1 1 1 1 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 8 1 1 1 1 1 7 1 8 1 2 1 1 1 2 2 2 2 1 2 2 2 2 2 5 2 2 2 9 8 2 2 8 2 2 2 2\n",
      " 2 2 8 2 1 2 8 2 2 1 2 8 2 3 9 2 2 2 3 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 3\n",
      " 3 3 3 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 1 7 5 4 4 6 8 4 1 4 4 4 6 4 4 4 4 4 4 4 4 4 4 5 7 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 1 9 5 3 5 5 1 5 5 5 5 5 5 5 5 5 1 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 2 2 6 6 4 4 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 1 1 7 7 7 1 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 9 7\n",
      " 7 8 3 7 7 9 7 7 7 7 7 7 7 7 7 8 7 8 8 8 8 2 8 1 6 2 5 2 8 3 8 8 1 8 8 2 8\n",
      " 8 8 8 9 5 8 8 8 8 8 9 9 9 1 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 5 5 9 9\n",
      " 3 9 9 9 9 9 7 9 9 9 9 9 9 9 1 9 9 9 1 9 9 9 9 5 9 9 2]\n"
     ]
    }
   ],
   "source": [
    "print(y_true)\n",
    "print((y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    }
   ],
   "source": [
    "Best parameters set found on development set:\n",
    "\n",
    "{'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 100}\n",
    "\n",
    "Grid scores on development set:\n",
    "\n",
    "0.890 (+/-0.083) for {'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 5}\n",
    "0.924 (+/-0.050) for {'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 10}\n",
    "0.953 (+/-0.035) for {'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 20}\n",
    "0.957 (+/-0.035) for {'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 50}\n",
    "0.965 (+/-0.044) for {'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 100}\n",
    "0.963 (+/-0.038) for {'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 200}\n",
    "0.963 (+/-0.042) for {'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 500}\n",
    "0.888 (+/-0.084) for {'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 5}\n",
    "0.910 (+/-0.049) for {'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 10}\n",
    "0.942 (+/-0.045) for {'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 20}\n",
    "0.943 (+/-0.044) for {'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 50}\n",
    "0.950 (+/-0.040) for {'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 100}\n",
    "0.949 (+/-0.053) for {'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 200}\n",
    "0.950 (+/-0.047) for {'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 500}\n",
    "0.864 (+/-0.053) for {'max_features': 'sqrt', 'min_samples_leaf': 10, 'n_estimators': 5}\n",
    "0.913 (+/-0.029) for {'max_features': 'sqrt', 'min_samples_leaf': 10, 'n_estimators': 10}\n",
    "0.920 (+/-0.044) for {'max_features': 'sqrt', 'min_samples_leaf': 10, 'n_estimators': 20}\n",
    "0.932 (+/-0.047) for {'max_features': 'sqrt', 'min_samples_leaf': 10, 'n_estimators': 50}\n",
    "0.937 (+/-0.047) for {'max_features': 'sqrt', 'min_samples_leaf': 10, 'n_estimators': 100}\n",
    "0.935 (+/-0.042) for {'max_features': 'sqrt', 'min_samples_leaf': 10, 'n_estimators': 200}\n",
    "0.934 (+/-0.047) for {'max_features': 'sqrt', 'min_samples_leaf': 10, 'n_estimators': 500}\n",
    "0.760 (+/-0.075) for {'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 5}\n",
    "0.830 (+/-0.047) for {'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 10}\n",
    "0.868 (+/-0.065) for {'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 20}\n",
    "0.880 (+/-0.068) for {'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 50}\n",
    "0.879 (+/-0.067) for {'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 100}\n",
    "0.895 (+/-0.057) for {'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 200}\n",
    "0.886 (+/-0.056) for {'max_features': 'sqrt', 'min_samples_leaf': 50, 'n_estimators': 500}\n",
    "0.684 (+/-0.037) for {'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 5}\n",
    "0.775 (+/-0.045) for {'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 10}\n",
    "0.833 (+/-0.037) for {'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 20}\n",
    "0.830 (+/-0.061) for {'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 50}\n",
    "0.835 (+/-0.069) for {'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 100}\n",
    "0.848 (+/-0.085) for {'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 200}\n",
    "0.851 (+/-0.063) for {'max_features': 'sqrt', 'min_samples_leaf': 100, 'n_estimators': 500}\n",
    "0.569 (+/-0.118) for {'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 5}\n",
    "0.700 (+/-0.102) for {'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 10}\n",
    "0.744 (+/-0.066) for {'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 20}\n",
    "0.798 (+/-0.065) for {'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 50}\n",
    "0.821 (+/-0.032) for {'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 100}\n",
    "0.821 (+/-0.087) for {'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 200}\n",
    "0.831 (+/-0.082) for {'max_features': 'sqrt', 'min_samples_leaf': 150, 'n_estimators': 500}\n",
    "0.561 (+/-0.138) for {'max_features': 'sqrt', 'min_samples_leaf': 200, 'n_estimators': 5}\n",
    "0.667 (+/-0.182) for {'max_features': 'sqrt', 'min_samples_leaf': 200, 'n_estimators': 10}\n",
    "0.714 (+/-0.113) for {'max_features': 'sqrt', 'min_samples_leaf': 200, 'n_estimators': 20}\n",
    "0.793 (+/-0.052) for {'max_features': 'sqrt', 'min_samples_leaf': 200, 'n_estimators': 50}\n",
    "0.793 (+/-0.066) for {'max_features': 'sqrt', 'min_samples_leaf': 200, 'n_estimators': 100}\n",
    "0.806 (+/-0.070) for {'max_features': 'sqrt', 'min_samples_leaf': 200, 'n_estimators': 200}\n",
    "0.793 (+/-0.055) for {'max_features': 'sqrt', 'min_samples_leaf': 200, 'n_estimators': 500}\n",
    "0.881 (+/-0.033) for {'max_features': 'log2', 'min_samples_leaf': 1, 'n_estimators': 5}\n",
    "0.929 (+/-0.044) for {'max_features': 'log2', 'min_samples_leaf': 1, 'n_estimators': 10}\n",
    "0.941 (+/-0.047) for {'max_features': 'log2', 'min_samples_leaf': 1, 'n_estimators': 20}\n",
    "0.959 (+/-0.029) for {'max_features': 'log2', 'min_samples_leaf': 1, 'n_estimators': 50}\n",
    "0.957 (+/-0.040) for {'max_features': 'log2', 'min_samples_leaf': 1, 'n_estimators': 100}\n",
    "0.963 (+/-0.036) for {'max_features': 'log2', 'min_samples_leaf': 1, 'n_estimators': 200}\n",
    "0.964 (+/-0.038) for {'max_features': 'log2', 'min_samples_leaf': 1, 'n_estimators': 500}\n",
    "0.864 (+/-0.053) for {'max_features': 'log2', 'min_samples_leaf': 5, 'n_estimators': 5}\n",
    "0.918 (+/-0.050) for {'max_features': 'log2', 'min_samples_leaf': 5, 'n_estimators': 10}\n",
    "0.930 (+/-0.042) for {'max_features': 'log2', 'min_samples_leaf': 5, 'n_estimators': 20}\n",
    "0.942 (+/-0.042) for {'max_features': 'log2', 'min_samples_leaf': 5, 'n_estimators': 50}\n",
    "0.953 (+/-0.040) for {'max_features': 'log2', 'min_samples_leaf': 5, 'n_estimators': 100}\n",
    "0.948 (+/-0.042) for {'max_features': 'log2', 'min_samples_leaf': 5, 'n_estimators': 200}\n",
    "0.952 (+/-0.043) for {'max_features': 'log2', 'min_samples_leaf': 5, 'n_estimators': 500}\n",
    "0.840 (+/-0.098) for {'max_features': 'log2', 'min_samples_leaf': 10, 'n_estimators': 5}\n",
    "0.897 (+/-0.083) for {'max_features': 'log2', 'min_samples_leaf': 10, 'n_estimators': 10}\n",
    "0.921 (+/-0.053) for {'max_features': 'log2', 'min_samples_leaf': 10, 'n_estimators': 20}\n",
    "0.927 (+/-0.049) for {'max_features': 'log2', 'min_samples_leaf': 10, 'n_estimators': 50}\n",
    "0.936 (+/-0.043) for {'max_features': 'log2', 'min_samples_leaf': 10, 'n_estimators': 100}\n",
    "0.939 (+/-0.043) for {'max_features': 'log2', 'min_samples_leaf': 10, 'n_estimators': 200}\n",
    "0.941 (+/-0.044) for {'max_features': 'log2', 'min_samples_leaf': 10, 'n_estimators': 500}\n",
    "0.743 (+/-0.143) for {'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 5}\n",
    "0.805 (+/-0.081) for {'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 10}\n",
    "0.842 (+/-0.059) for {'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 20}\n",
    "0.890 (+/-0.047) for {'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 50}\n",
    "0.903 (+/-0.053) for {'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 100}\n",
    "0.901 (+/-0.055) for {'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 200}\n",
    "0.914 (+/-0.052) for {'max_features': 'log2', 'min_samples_leaf': 50, 'n_estimators': 500}\n",
    "0.683 (+/-0.122) for {'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 5}\n",
    "0.771 (+/-0.071) for {'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 10}\n",
    "0.819 (+/-0.055) for {'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 20}\n",
    "0.869 (+/-0.040) for {'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 50}\n",
    "0.881 (+/-0.050) for {'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 100}\n",
    "0.881 (+/-0.060) for {'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 200}\n",
    "0.887 (+/-0.051) for {'max_features': 'log2', 'min_samples_leaf': 100, 'n_estimators': 500}\n",
    "0.611 (+/-0.108) for {'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 5}\n",
    "0.719 (+/-0.080) for {'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 10}\n",
    "0.828 (+/-0.072) for {'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 20}\n",
    "0.837 (+/-0.047) for {'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 50}\n",
    "0.864 (+/-0.066) for {'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 100}\n",
    "0.865 (+/-0.059) for {'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 200}\n",
    "0.883 (+/-0.053) for {'max_features': 'log2', 'min_samples_leaf': 150, 'n_estimators': 500}\n",
    "0.548 (+/-0.168) for {'max_features': 'log2', 'min_samples_leaf': 200, 'n_estimators': 5}\n",
    "0.661 (+/-0.101) for {'max_features': 'log2', 'min_samples_leaf': 200, 'n_estimators': 10}\n",
    "0.763 (+/-0.033) for {'max_features': 'log2', 'min_samples_leaf': 200, 'n_estimators': 20}\n",
    "0.828 (+/-0.045) for {'max_features': 'log2', 'min_samples_leaf': 200, 'n_estimators': 50}\n",
    "0.841 (+/-0.039) for {'max_features': 'log2', 'min_samples_leaf': 200, 'n_estimators': 100}\n",
    "0.861 (+/-0.044) for {'max_features': 'log2', 'min_samples_leaf': 200, 'n_estimators': 200}\n",
    "0.869 (+/-0.064) for {'max_features': 'log2', 'min_samples_leaf': 200, 'n_estimators': 500}\n",
    "0.898 (+/-0.034) for {'max_features': 0.2, 'min_samples_leaf': 1, 'n_estimators': 5}\n",
    "0.929 (+/-0.040) for {'max_features': 0.2, 'min_samples_leaf': 1, 'n_estimators': 10}\n",
    "0.943 (+/-0.052) for {'max_features': 0.2, 'min_samples_leaf': 1, 'n_estimators': 20}\n",
    "0.949 (+/-0.051) for {'max_features': 0.2, 'min_samples_leaf': 1, 'n_estimators': 50}\n",
    "0.952 (+/-0.053) for {'max_features': 0.2, 'min_samples_leaf': 1, 'n_estimators': 100}\n",
    "0.956 (+/-0.045) for {'max_features': 0.2, 'min_samples_leaf': 1, 'n_estimators': 200}\n",
    "0.954 (+/-0.052) for {'max_features': 0.2, 'min_samples_leaf': 1, 'n_estimators': 500}\n",
    "0.885 (+/-0.078) for {'max_features': 0.2, 'min_samples_leaf': 5, 'n_estimators': 5}\n",
    "0.914 (+/-0.046) for {'max_features': 0.2, 'min_samples_leaf': 5, 'n_estimators': 10}\n",
    "0.930 (+/-0.064) for {'max_features': 0.2, 'min_samples_leaf': 5, 'n_estimators': 20}\n",
    "0.937 (+/-0.048) for {'max_features': 0.2, 'min_samples_leaf': 5, 'n_estimators': 50}\n",
    "0.939 (+/-0.043) for {'max_features': 0.2, 'min_samples_leaf': 5, 'n_estimators': 100}\n",
    "0.934 (+/-0.049) for {'max_features': 0.2, 'min_samples_leaf': 5, 'n_estimators': 200}\n",
    "0.942 (+/-0.044) for {'max_features': 0.2, 'min_samples_leaf': 5, 'n_estimators': 500}\n",
    "0.869 (+/-0.047) for {'max_features': 0.2, 'min_samples_leaf': 10, 'n_estimators': 5}\n",
    "0.896 (+/-0.048) for {'max_features': 0.2, 'min_samples_leaf': 10, 'n_estimators': 10}\n",
    "0.917 (+/-0.059) for {'max_features': 0.2, 'min_samples_leaf': 10, 'n_estimators': 20}\n",
    "0.913 (+/-0.051) for {'max_features': 0.2, 'min_samples_leaf': 10, 'n_estimators': 50}\n",
    "0.923 (+/-0.062) for {'max_features': 0.2, 'min_samples_leaf': 10, 'n_estimators': 100}\n",
    "0.920 (+/-0.051) for {'max_features': 0.2, 'min_samples_leaf': 10, 'n_estimators': 200}\n",
    "0.919 (+/-0.053) for {'max_features': 0.2, 'min_samples_leaf': 10, 'n_estimators': 500}\n",
    "0.772 (+/-0.110) for {'max_features': 0.2, 'min_samples_leaf': 50, 'n_estimators': 5}\n",
    "0.796 (+/-0.078) for {'max_features': 0.2, 'min_samples_leaf': 50, 'n_estimators': 10}\n",
    "0.801 (+/-0.120) for {'max_features': 0.2, 'min_samples_leaf': 50, 'n_estimators': 20}\n",
    "0.838 (+/-0.094) for {'max_features': 0.2, 'min_samples_leaf': 50, 'n_estimators': 50}\n",
    "0.819 (+/-0.091) for {'max_features': 0.2, 'min_samples_leaf': 50, 'n_estimators': 100}\n",
    "0.834 (+/-0.083) for {'max_features': 0.2, 'min_samples_leaf': 50, 'n_estimators': 200}\n",
    "0.835 (+/-0.100) for {'max_features': 0.2, 'min_samples_leaf': 50, 'n_estimators': 500}\n",
    "0.633 (+/-0.158) for {'max_features': 0.2, 'min_samples_leaf': 100, 'n_estimators': 5}\n",
    "0.686 (+/-0.125) for {'max_features': 0.2, 'min_samples_leaf': 100, 'n_estimators': 10}\n",
    "0.749 (+/-0.041) for {'max_features': 0.2, 'min_samples_leaf': 100, 'n_estimators': 20}\n",
    "0.733 (+/-0.133) for {'max_features': 0.2, 'min_samples_leaf': 100, 'n_estimators': 50}\n",
    "0.745 (+/-0.070) for {'max_features': 0.2, 'min_samples_leaf': 100, 'n_estimators': 100}\n",
    "0.751 (+/-0.091) for {'max_features': 0.2, 'min_samples_leaf': 100, 'n_estimators': 200}\n",
    "0.765 (+/-0.071) for {'max_features': 0.2, 'min_samples_leaf': 100, 'n_estimators': 500}\n",
    "0.550 (+/-0.174) for {'max_features': 0.2, 'min_samples_leaf': 150, 'n_estimators': 5}\n",
    "0.670 (+/-0.097) for {'max_features': 0.2, 'min_samples_leaf': 150, 'n_estimators': 10}\n",
    "0.648 (+/-0.171) for {'max_features': 0.2, 'min_samples_leaf': 150, 'n_estimators': 20}\n",
    "0.679 (+/-0.055) for {'max_features': 0.2, 'min_samples_leaf': 150, 'n_estimators': 50}\n",
    "0.712 (+/-0.053) for {'max_features': 0.2, 'min_samples_leaf': 150, 'n_estimators': 100}\n",
    "0.697 (+/-0.061) for {'max_features': 0.2, 'min_samples_leaf': 150, 'n_estimators': 200}\n",
    "0.724 (+/-0.067) for {'max_features': 0.2, 'min_samples_leaf': 150, 'n_estimators': 500}\n",
    "0.519 (+/-0.181) for {'max_features': 0.2, 'min_samples_leaf': 200, 'n_estimators': 5}\n",
    "0.559 (+/-0.148) for {'max_features': 0.2, 'min_samples_leaf': 200, 'n_estimators': 10}\n",
    "0.635 (+/-0.086) for {'max_features': 0.2, 'min_samples_leaf': 200, 'n_estimators': 20}\n",
    "0.559 (+/-0.116) for {'max_features': 0.2, 'min_samples_leaf': 200, 'n_estimators': 50}\n",
    "0.620 (+/-0.117) for {'max_features': 0.2, 'min_samples_leaf': 200, 'n_estimators': 100}\n",
    "0.660 (+/-0.074) for {'max_features': 0.2, 'min_samples_leaf': 200, 'n_estimators': 200}\n",
    "0.677 (+/-0.035) for {'max_features': 0.2, 'min_samples_leaf': 200, 'n_estimators': 500}\n",
    "\n",
    "Detailed classification report:\n",
    "\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "          0       1.00      0.97      0.99        39\n",
    "          1       0.96      0.96      0.96        48\n",
    "          2       0.96      1.00      0.98        45\n",
    "          3       0.96      1.00      0.98        49\n",
    "          4       0.97      0.97      0.97        36\n",
    "          5       0.97      0.97      0.97        37\n",
    "          6       1.00      0.96      0.98        45\n",
    "          7       0.98      1.00      0.99        51\n",
    "          8       0.97      0.93      0.95        30\n",
    "          9       1.00      0.98      0.99        54\n",
    "\n",
    "avg / total       0.98      0.98      0.98       434\n",
    "\n",
    "\n",
    "使用测试集验证平均准确率:\n",
    "Random Forest {'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 100}\n",
    "\t 测试样本个数为： 434 \n",
    "\t 预测错误个数为： 10 \n",
    "\t 预测错误率为： 2.30% \n",
    "\t 预测准确率为： 97.70%\n",
    "0.9769585253456221"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
